# üöÄ Ambiente BigData Integrado

Este projeto fornece um ambiente completo de Big Data usando Docker, integrando Airflow, MinIO, Jenkins, PySpark e Jupyter Notebook para desenvolvimento e processamento de dados em larga escala.

## üìã Vis√£o Geral

O ambiente inclui os seguintes servi√ßos integrados:

- **üåä Apache Airflow 2.7.0**: Orquestra√ß√£o de workflows e pipelines de dados
- **üì¶ MinIO**: Storage de objetos compat√≠vel com S3
- **üîß Jenkins**: CI/CD para automa√ß√£o de builds e deploys
- **‚ö° Apache Spark 3.4.0**: Processamento distribu√≠do de dados
- **üìì Jupyter Notebook**: Desenvolvimento interativo e an√°lise de dados (PySpark)
- **üêò PostgreSQL 13**: Banco de dados para metadados do Airflow
- **üìÆ Redis**: Message broker para Celery (Airflow)

## ÔøΩ Configura√ß√µes Dispon√≠veis

### üî¨ **Ambiente M√≠nimo** (`make minimal`)
- **Recursos:** 3-4GB RAM, 2 CPUs, 5-8GB disco
- **Servi√ßos:** Airflow Standalone + Jupyter/Spark Local + MinIO + PostgreSQL
- **Ideal para:** Desenvolvimento b√°sico, aprendizado, m√°quinas com poucos recursos

### üß™ **Ambiente Lab** (`make lab`) 
- **Recursos:** 6-8GB RAM, 4 CPUs, 10-15GB disco
- **Servi√ßos:** Airflow + Spark Cluster + MinIO + Jupyter + Redis
- **Ideal para:** Laborat√≥rio, testes, desenvolvimento intermedi√°rio

### üè≠ **Ambiente Completo** (`make start`)
- **Recursos:** 10-12GB RAM, 6-8 cores, 20GB+ disco
- **Servi√ßos:** Todos os servi√ßos incluindo Jenkins e Workers distribu√≠dos
- **Ideal para:** Produ√ß√£o, desenvolvimento avan√ßado

üí° **Use `make requirements` para ver detalhes completos dos recursos.**

üí° **Use `make requirements` para ver detalhes completos dos recursos.**

## ‚öôÔ∏è Configura√ß√£o

### üìù Arquivo de Vari√°veis de Ambiente

Antes de iniciar o ambiente, configure as vari√°veis de ambiente:

```bash
# Copie o arquivo de exemplo
cp .env.example .env

# Edite com suas configura√ß√µes
nano .env
```

**Principais configura√ß√µes no arquivo `.env`:**

```bash
# IP do servidor (para acesso externo)
SERVER_IP=192.168.1.22

# Senhas personalizadas (ALTERE!)
POSTGRES_PASSWORD=sua_senha_postgres_aqui
AIRFLOW_ADMIN_PASSWORD=sua_senha_airflow_aqui
MINIO_ROOT_PASSWORD=sua_senha_minio_aqui

# Portas (opcional - s√≥ mude se houver conflito)
AIRFLOW_PORT=8080
JUPYTER_PORT=8888
MINIO_CONSOLE_PORT=9001
```

‚ö†Ô∏è **Importante:** Sempre altere as senhas padr√£o em ambientes de produ√ß√£o!

## üöÄ Instala√ß√£o e Uso

### 1. Clone ou baixe o projeto

```bash
git clone <seu-repositorio>
cd containers
```

### 2. Inicie o ambiente

#### Op√ß√£o A: Usando Makefile (Recomendado)
```bash
# Ver todos os comandos dispon√≠veis
make help

# Ver requisitos de sistema
make requirements

# Escolher configura√ß√£o baseada nos seus recursos:
make minimal     # Para 3-4GB RAM (b√°sico)
make lab         # Para 6-8GB RAM (laborat√≥rio)  
make start       # Para 10GB+ RAM (completo)

# Verificar status
make status
```

#### Op√ß√£o B: Usando scripts diretamente
```bash
./scripts/start.sh
```

O sistema ir√°:
- Verificar depend√™ncias
- Criar diret√≥rios necess√°rios
- Configurar vari√°veis de ambiente
- Inicializar todos os servi√ßos em ordem
- Aguardar que todos estejam prontos

### 3. Acesse os servi√ßos

Ap√≥s a inicializa√ß√£o completa, os servi√ßos estar√£o dispon√≠veis em:

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://SERVER_IP:8080 | admin/admin |
| **Spark Master UI** | http://SERVER_IP:8081 | - |
| **MinIO Console** | http://SERVER_IP:9001 | minioadmin/minioadmin123 |
| **Jenkins** | http://SERVER_IP:8082 | admin/admin |
| **Jupyter Notebook** | http://SERVER_IP:8888 | sem senha |
| **Flower (Celery)** | http://SERVER_IP:5555 | - |

üìù **Nota:** Substitua `SERVER_IP` pelo IP configurado no arquivo `.env` (exemplo: 192.168.1.22 ou localhost)

üí° **Dica:** Use `make ports` para ver as URLs exatas configuradas no seu ambiente.

## üìÅ Estrutura do Projeto

```
containers/
‚îú‚îÄ‚îÄ docker-compose.yml          # Configura√ß√£o completa (produ√ß√£o)
‚îú‚îÄ‚îÄ docker-compose.minimal.yml  # Configura√ß√£o m√≠nima (4GB RAM)
‚îú‚îÄ‚îÄ docker-compose.lab.yml      # Configura√ß√£o laborat√≥rio (6GB RAM)
‚îú‚îÄ‚îÄ .env                       # Vari√°veis de ambiente (configurado pelo usu√°rio)
‚îú‚îÄ‚îÄ .env.example                # Template de vari√°veis de ambiente
‚îú‚îÄ‚îÄ Makefile                   # Automa√ß√£o de comandos
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îú‚îÄ‚îÄ PARAMETRIZACAO.md          # Documenta√ß√£o de parametriza√ß√£o
‚îú‚îÄ‚îÄ airflow/                   # Configura√ß√µes do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dags/                 # DAGs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ plugins/              # Plugins customizados
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Configura√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      # Depend√™ncias Python
‚îú‚îÄ‚îÄ jenkins/                   # Configura√ß√µes do Jenkins
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile           # Imagem customizada
‚îÇ   ‚îú‚îÄ‚îÄ plugins.txt          # Lista de plugins
‚îÇ   ‚îî‚îÄ‚îÄ init.groovy.d/       # Scripts de inicializa√ß√£o
‚îú‚îÄ‚îÄ spark/                     # Configura√ß√µes do Spark
‚îÇ   ‚îú‚îÄ‚îÄ apps/                # Aplica√ß√µes Spark
‚îÇ   ‚îú‚îÄ‚îÄ conf/                # Configura√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ data/                # Dados do Spark
‚îú‚îÄ‚îÄ jupyter/                   # Configura√ß√µes do Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/           # Notebooks Jupyter
‚îÇ   ‚îî‚îÄ‚îÄ config/              # Configura√ß√µes
‚îú‚îÄ‚îÄ scripts/                   # Scripts utilit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ start.sh             # Inicializar ambiente
‚îÇ   ‚îú‚îÄ‚îÄ stop.sh              # Parar ambiente
‚îÇ   ‚îú‚îÄ‚îÄ status.sh            # Status dos servi√ßos
‚îÇ   ‚îî‚îÄ‚îÄ setup-minio.sh       # Configura√ß√£o do MinIO
‚îú‚îÄ‚îÄ Makefile                   # Automa√ß√£o de comandos
‚îú‚îÄ‚îÄ data/                      # Dados compartilhados
‚îî‚îÄ‚îÄ logs/                      # Logs dos servi√ßos
```

## üõ†Ô∏è Comandos √öteis

### üìã Comandos Principais

```bash
# Ver todos os comandos dispon√≠veis
make help

# Iniciar ambientes
make minimal            # Ambiente m√≠nimo (4GB RAM)
make lab               # Ambiente laborat√≥rio (6GB RAM)  
make start             # Ambiente completo (10GB+ RAM)

# Parar ambientes
make stop              # Para o ambiente atual
make stop-minimal      # Para especificamente o ambiente m√≠nimo
make stop-lab          # Para especificamente o ambiente lab
make stop-all          # Para TODOS os containers de todos os ambientes

# Status e monitoramento
make health            # Verifica sa√∫de de todos os servi√ßos
make status            # Status detalhado via script
make ps                # Lista containers do ambiente atual
make ps-all            # Lista containers de TODOS os ambientes
make ports             # Mostra portas e URLs de acesso
```

### üìä Monitoramento e Logs

```bash
# Logs gerais
make logs              # Ver logs de todos os servi√ßos
make logs-airflow      # Logs espec√≠ficos do Airflow
make logs-spark        # Logs espec√≠ficos do Spark
make logs-jupyter      # Logs do Jupyter
make logs-minio        # Logs do MinIO
make logs-jenkins      # Logs do Jenkins

# Recursos
make top               # Uso de recursos dos containers
make info              # Informa√ß√µes do ambiente
make version           # Vers√µes dos componentes
```

### üîß Desenvolvimento

```bash
# Acessar shells dos servi√ßos
make airflow-shell     # Acessar shell do Airflow
make spark-shell       # Acessar Spark shell
make jupyter-shell     # Acessar shell do Jupyter
make minio-shell       # Acessar shell do MinIO

# Opera√ß√µes com Spark
make submit-spark      # Submeter job Spark de exemplo

# Reiniciar servi√ßos espec√≠ficos
make restart-airflow   # Reinicia apenas o Airflow
make restart-spark     # Reinicia cluster Spark
make restart-jupyter   # Reinicia Jupyter
```

### üß™ Testes e Valida√ß√£o

```bash
# Testes de integra√ß√£o
make test              # Executa todos os testes
make test-airflow      # Testa Airflow
make test-spark        # Testa cluster Spark
make test-minio        # Testa MinIO

# Verifica√ß√µes
make check             # Verifica configura√ß√£o e depend√™ncias
make requirements      # Mostra requisitos de sistema
```

### üóÇÔ∏è Manuten√ß√£o e Dados

```bash
# Backup e restore
make backup            # Fazer backup dos dados
make clean             # Limpar dados (CUIDADO!)
make clean-images      # Remove imagens n√£o utilizadas

# Atualiza√ß√µes
make pull              # Atualiza todas as imagens
make rebuild           # Rebuild completo (pull + build)
```

### üåê Comandos de Rede

```bash
# Portas e acesso
make ports             # Lista portas utilizadas
make open              # Abre todas as interfaces web (Linux)

# Exemplo de sa√≠da do make ports:
# ‚Ä¢ Airflow:     http://${SERVER_IP}:8080
# ‚Ä¢ Spark UI:    http://${SERVER_IP}:8081  
# ‚Ä¢ MinIO:       http://${SERVER_IP}:9001
# ‚Ä¢ Jupyter:     http://${SERVER_IP}:8888
```
```

### Gerenciamento do Ambiente (Scripts)

```bash
# Iniciar ambiente completo
./scripts/start.sh

# Verificar status
./scripts/status.sh

# Parar ambiente
./scripts/stop.sh

# Parar e limpar todos os dados
./scripts/stop.sh --clean
```

## üéØ Comandos Espec√≠ficos por Servi√ßo

O ambiente oferece comandos granulares para gerenciar cada servi√ßo individualmente:

### üêò PostgreSQL
```bash
# Gerenciamento b√°sico
make start-postgres    # Inicia apenas PostgreSQL
make stop-postgres     # Para PostgreSQL  
make restart-postgres  # Reinicia PostgreSQL
make health-postgres   # Verifica sa√∫de
make logs-postgres     # Visualiza logs

# Acesso e debug
make shell-postgres    # Conecta via psql
make debug-postgres    # Debug completo
make reset-postgres    # Reset completo (REMOVE DADOS!)
make backup-postgres   # Backup dos dados
```

### üìÆ Redis  
```bash
# Gerenciamento b√°sico
make start-redis       # Inicia apenas Redis
make stop-redis        # Para Redis
make restart-redis     # Reinicia Redis  
make health-redis      # Verifica sa√∫de
make logs-redis        # Visualiza logs

# Acesso
make shell-redis       # Conecta via redis-cli
```

### üóÇÔ∏è MinIO
```bash
# Gerenciamento b√°sico
make start-minio       # Inicia apenas MinIO
make stop-minio        # Para MinIO
make restart-minio     # Reinicia MinIO
make health-minio      # Verifica sa√∫de  
make logs-minio        # Visualiza logs

# Acesso e manuten√ß√£o
make shell-minio       # Shell no container
make open-minio        # Abre interface web
make debug-minio       # Debug completo
make backup-minio      # Backup dos dados
make reset-minio       # Reset completo (REMOVE DADOS!)
```

### ‚úàÔ∏è Airflow
```bash
# Gerenciamento b√°sico (inclui depend√™ncias)
make start-airflow     # Inicia Airflow + PostgreSQL + Redis
make stop-airflow      # Para todos os servi√ßos Airflow  
make restart-airflow   # Reinicia Airflow
make health-airflow    # Verifica sa√∫de de todos os componentes

# Logs espec√≠ficos
make logs-airflow-webserver    # Logs do webserver
make logs-airflow-scheduler    # Logs do scheduler  
make logs-airflow-worker       # Logs do worker

# Acesso e manuten√ß√£o
make shell-airflow     # Shell no container
make open-airflow      # Abre interface web
make debug-airflow     # Debug completo
make backup-airflow    # Backup configura√ß√µes e logs
make check-deps-airflow # Verifica depend√™ncias
```

### ‚ö° Spark
```bash
# Gerenciamento b√°sico
make start-spark       # Inicia cluster Spark completo
make stop-spark        # Para cluster Spark
make restart-spark     # Reinicia cluster
make health-spark      # Verifica sa√∫de do cluster

# Logs espec√≠ficos  
make logs-spark-master   # Logs do master
make logs-spark-worker   # Logs dos workers

# Acesso e manuten√ß√£o
make shell-spark       # Shell no Spark Master
make open-spark        # Abre Spark UI
make debug-spark       # Debug completo
make check-deps-spark  # Verifica depend√™ncias
```

### üìì Jupyter
```bash
# Gerenciamento b√°sico
make start-jupyter     # Inicia Jupyter
make stop-jupyter      # Para Jupyter
make restart-jupyter   # Reinicia Jupyter
make health-jupyter    # Verifica sa√∫de
make logs-jupyter      # Visualiza logs

# Acesso
make shell-jupyter     # Shell no container
make open-jupyter      # Abre interface web (senha: jupyter)
```

### üèóÔ∏è Jenkins
```bash
# Gerenciamento b√°sico
make start-jenkins     # Inicia Jenkins
make stop-jenkins      # Para Jenkins  
make restart-jenkins   # Reinicia Jenkins
make health-jenkins    # Verifica sa√∫de
make logs-jenkins      # Visualiza logs

# Acesso
make shell-jenkins     # Shell no container
make open-jenkins      # Abre interface web
```

## üîß Comandos de Status Consolidado

```bash
# Status por categoria
make status-database      # PostgreSQL + Redis
make status-storage       # MinIO
make status-compute       # Spark + Jupyter  
make status-orchestration # Airflow + Jenkins

# Verifica√ß√£o de depend√™ncias
make check-deps-airflow   # Depend√™ncias do Airflow
make check-deps-spark     # Depend√™ncias do Spark
```

## üíæ Backup e Restore por Servi√ßo

```bash
# Backups individuais
make backup-postgres      # Backup PostgreSQL
make backup-minio         # Backup MinIO
make backup-airflow       # Backup Airflow

# Backups completos
make full-backup-postgres # Dados + volume PostgreSQL
make full-backup-minio    # Backup completo MinIO
make full-backup-airflow  # Configura√ß√µes + logs Airflow

# Backup de todo ambiente
make backup-all           # Backup completo de tudo

# Gerenciamento de backups
make list-backups         # Lista todos os backups
make clean-old-backups    # Remove backups >7 dias
```

## üö® Troubleshooting por Servi√ßo

```bash
# Debug espec√≠fico
make debug-postgres       # Debug PostgreSQL completo
make debug-minio          # Debug MinIO completo  
make debug-airflow        # Debug Airflow completo
make debug-spark          # Debug Spark completo

# Reset de servi√ßos (CUIDADO!)
make reset-postgres       # Remove todos os dados PostgreSQL
make reset-minio          # Remove todos os dados MinIO
make reset-airflow        # Remove logs e configura√ß√µes

# Rebuild de containers
make rebuild-postgres     # Rebuild PostgreSQL
make rebuild-minio        # Rebuild MinIO
make rebuild-airflow      # Rebuild Airflow
make rebuild-spark        # Rebuild Spark  
make rebuild-jupyter      # Rebuild Jupyter
```

### Docker Compose (Comandos Manuais)

```bash
# Ver logs de um servi√ßo espec√≠fico
docker-compose logs -f airflow-webserver

# Reiniciar um servi√ßo
docker-compose restart spark-master

# Acessar container
docker-compose exec jupyter bash

# Ver status dos containers
docker-compose ps
```

### Spark

```bash
# Submeter job Spark (usando vari√°veis parametrizadas)
docker-compose exec spark-master spark-submit \
    --master ${SPARK_MASTER_URL} \
    ${SPARK_APPS_PATH}/example_spark_minio.py

# Acessar Spark shell
docker-compose exec spark-master spark-shell \
    --master ${SPARK_MASTER_URL}

# Alternativa com valores fixos (se preferir)
# docker-compose exec spark-master spark-submit \
#     --master spark://spark-master:7077 \
#     /opt/bitnami/spark/apps/example_spark_minio.py
```

### MinIO

```bash
# Listar buckets
docker-compose exec minio mc ls myminio

# Copiar arquivo para bucket
docker-compose exec minio mc cp /data/arquivo.csv myminio/data-lake/
```

## üìä Exemplos de Uso

### 1. DAG do Airflow

Um DAG de exemplo est√° inclu√≠do em `airflow/dags/example_bigdata_integration.py` que demonstra:
- Teste de conex√£o com MinIO
- Execu√ß√£o de job Spark
- Gera√ß√£o de relat√≥rios

### 2. Notebook Jupyter

Um notebook de exemplo est√° inclu√≠do em `jupyter/notebooks/BigData_Integration_Example.ipynb` que demonstra:
- Conex√£o com Spark
- Processamento de dados
- Salvamento no MinIO
- Visualiza√ß√µes

### 3. Pipeline Jenkins

Um pipeline de exemplo √© criado automaticamente que demonstra:
- Build e teste de aplica√ß√µes
- Deploy para Spark
- Backup no MinIO

## üîÑ Fluxo de Desenvolvimento

1. **Desenvolvimento**: Use Jupyter para explora√ß√£o e prototipagem
2. **Orquestra√ß√£o**: Crie DAGs no Airflow para workflows automatizados
3. **Processamento**: Desenvolva aplica√ß√µes Spark para processamento em larga escala
4. **CI/CD**: Use Jenkins para automa√ß√£o de builds e deploys
5. **Storage**: Armazene dados e resultados no MinIO

## üîß Configura√ß√µes Avan√ßadas

### Escalabilidade do Spark

Para adicionar mais workers Spark, edite o `docker-compose.yml`:

```yaml
spark-worker-3:
  image: bitnami/spark:3.4.0
  container_name: bigdata_spark_worker_3
  # ... configura√ß√µes similares aos outros workers
```

### Configura√ß√µes do Airflow

Personalize configura√ß√µes em `airflow/config/airflow.cfg`:
- Executors
- Conex√µes de banco
- Configura√ß√µes de email
- Plugins

### Autentica√ß√£o

Para produ√ß√£o, considere:
- Configurar autentica√ß√£o LDAP/OAuth
- Usar secrets managers
- Implementar HTTPS
- Configurar firewalls

## üìà Monitoramento

### Logs

```bash
# Todos os logs
docker-compose logs -f

# Logs espec√≠ficos
docker-compose logs -f airflow-scheduler
docker-compose logs -f spark-master
```

### M√©tricas

- **Airflow**: Interface web com m√©tricas de DAGs
- **Spark**: Spark UI com m√©tricas de jobs
- **MinIO**: Console com estat√≠sticas de storage
- **Jenkins**: Interface com hist√≥rico de builds

## üö® Troubleshooting

### Problemas Comuns

1. **Porta j√° em uso**
   ```bash
   # Verificar portas ocupadas
   netstat -tulpn | grep :8080
   ```

2. **Mem√≥ria insuficiente**
   ```bash
   # Verificar uso de mem√≥ria
   docker stats
   ```

3. **Permiss√µes do Airflow**
   ```bash
   # Corrigir permiss√µes
   sudo chown -R 1000:0 airflow/
   ```

4. **Containers n√£o iniciam**
   ```bash
   # Ver logs detalhados
   docker-compose logs [servi√ßo]
   ```

### Recupera√ß√£o

```bash
# Restart completo
./scripts/stop.sh
./scripts/start.sh

# Limpeza completa (CUIDADO: remove todos os dados)
make clean
make start
```

## üîß Troubleshooting

### üö® Problemas Comuns

#### 1. **Permission denied while trying to connect to Docker daemon**
```bash
# Solu√ß√£o: Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER

# Depois fa√ßa logout/login ou:
newgrp docker

# Verificar se funcionou:
groups | grep docker
```

#### 2. **Erro "Port already in use"**
```bash
# Verificar portas ocupadas
sudo netstat -tlnp | grep :8080

# Parar todos os containers
make stop-all

# Ou alterar portas no arquivo .env
nano .env
```

#### 3. **Containers n√£o iniciam (recursos insuficientes)**
```bash
# Verificar recursos dispon√≠veis
make requirements

# Usar ambiente mais leve
make minimal  # Em vez de make start
```

#### 4. **Airflow n√£o carrega DAGs**
```bash
# Verificar logs do Airflow
make logs-airflow

# Verificar permiss√µes da pasta dags
ls -la airflow/dags/

# Corrigir permiss√µes se necess√°rio
sudo chown -R $USER:$USER airflow/
```

### üîç Comandos de Diagn√≥stico

```bash
# Status completo do sistema
make health               # Status de todos os servi√ßos
make ps-all              # Containers de todos os ambientes
make check               # Verificar depend√™ncias
make info                # Informa√ß√µes do ambiente

# Verificar recursos
make top                 # Uso de CPU/RAM
docker system df         # Uso de disco

# Logs espec√≠ficos
make logs-[servi√ßo]      # Logs de servi√ßo espec√≠fico
```

### üíæ **Em Caso de Problemas Graves**

```bash
# Reset completo (CUIDADO: remove todos os dados!)
make stop-all
make clean

# Reinstalar do zero
cp .env.example .env
nano .env               # Configure suas vari√°veis
make minimal           # Come√ßar com ambiente simples
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo LICENSE para detalhes.

## üÜò Suporte

Para problemas ou d√∫vidas:
1. Verifique a se√ß√£o de troubleshooting
2. Consulte os logs dos servi√ßos
3. Abra uma issue no reposit√≥rio

## üîó Recursos √öteis

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [MinIO Documentation](https://docs.min.io/)
- [Jenkins Documentation](https://www.jenkins.io/doc/)
- [Jupyter Documentation](https://jupyter.readthedocs.io/)

---

**üéâ Aproveite seu ambiente BigData integrado!**