# Makefile para gerenciar o ambiente BigData
# Uso: make <comando>

.PHONY: help start stop restart status clean logs build install check health test backup restore

# Carregar variÃ¡veis do .env se existir, mas permitir override
ifneq ($(wildcard .env),)
    include .env
    export
endif

# Definir variÃ¡veis padrÃ£o se nÃ£o definidas (podem ser sobrescritas na linha de comando)
SERVER_IP ?= localhost
AIRFLOW_PORT ?= 8080
SPARK_UI_PORT ?= 8081
MINIO_CONSOLE_PORT ?= 9001
JENKINS_PORT ?= 8082
JUPYTER_PORT ?= 8888
FLOWER_PORT ?= 5555

# VariÃ¡veis
COMPOSE_FILE = docker-compose.yml
PROJECT_NAME = bigdata
SERVICES = postgres redis minio airflow-webserver airflow-scheduler airflow-worker spark-master spark-worker-1 spark-worker-2 jupyter jenkins

# Cores para output
GREEN = \033[0;32m
YELLOW = \033[1;33m
RED = \033[0;31m
BLUE = \033[0;34m
NC = \033[0m # No Color

# Verifica se arquivo .env existe
.PHONY: check-env
check-env:
	@if [ ! -f .env ]; then \
		echo "$(RED)âš ï¸ Arquivo .env nÃ£o encontrado!$(NC)"; \
		echo "$(YELLOW)ğŸ“ Configure as variÃ¡veis de ambiente:$(NC)"; \
		echo "   cp env.example .env"; \
		echo "   nano .env"; \
		echo ""; \
		echo "$(BLUE)ğŸ’¡ Edite o IP do servidor e senhas no arquivo .env$(NC)"; \
		exit 1; \
	fi

# Target padrÃ£o
.DEFAULT_GOAL := help

## ğŸ“‹ Comandos Principais

lab: check-env ## ğŸ§ª Inicia ambiente de laboratÃ³rio (recursos mÃ­nimos)
	@echo "$(BLUE)ğŸ§ª Iniciando ambiente de laboratÃ³rio...$(NC)"
	@echo "$(YELLOW)ğŸ’¾ Recursos otimizados: ~6GB RAM, 4 CPUs$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.lab.yml up -d; \
	else \
		echo "$(YELLOW)âš ï¸  UsuÃ¡rio nÃ£o estÃ¡ no grupo docker. Usando sudo...$(NC)"; \
		sudo docker-compose -f docker-compose.lab.yml up -d; \
	fi
	@echo "$(GREEN)âœ… Ambiente de laboratÃ³rio iniciado!$(NC)"
	@echo "$(BLUE)ğŸŒ Acesse:$(NC)"
	@if [ -f .env ]; then \
		. ./.env; \
		echo "  â€¢ Airflow:  http://$${SERVER_IP:-localhost}:$${AIRFLOW_PORT:-8080} (admin/admin)"; \
		echo "  â€¢ Spark UI: http://$${SERVER_IP:-localhost}:$${SPARK_UI_PORT:-8081}"; \
		echo "  â€¢ MinIO:    http://$${SERVER_IP:-localhost}:$${MINIO_CONSOLE_PORT:-9001} (minioadmin/minioadmin123)"; \
		echo "  â€¢ Jupyter:  http://$${SERVER_IP:-localhost}:$${JUPYTER_PORT:-8888}"; \
	else \
		echo "  â€¢ Airflow:  http://localhost:8080 (admin/admin)"; \
		echo "  â€¢ Spark UI: http://localhost:8081"; \
		echo "  â€¢ MinIO:    http://localhost:9001 (minioadmin/minioadmin123)"; \
		echo "  â€¢ Jupyter:  http://localhost:8888"; \
	fi

stop-lab: ## ğŸ›‘ Para ambiente de laboratÃ³rio
	@echo "$(YELLOW)ğŸ›‘ Parando ambiente de laboratÃ³rio...$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.lab.yml down; \
	else \
		sudo docker-compose -f docker-compose.lab.yml down; \
	fi

minimal: check-env ## ğŸ”¬ Ambiente mÃ­nimo (4GB RAM, 2 CPUs)
	@echo "$(BLUE)ğŸ”¬ Iniciando ambiente mÃ­nimo...$(NC)"
	@echo "$(YELLOW)ğŸ’¾ Ultra otimizado: ~4GB RAM, 2 CPUs$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.minimal.yml up -d; \
	else \
		sudo docker-compose -f docker-compose.minimal.yml up -d; \
	fi
	@echo "$(GREEN)âœ… Ambiente mÃ­nimo iniciado!$(NC)"
	@echo "$(BLUE)ğŸŒ Acesse:$(NC)"
	@if [ -f .env ]; then \
		. ./.env; \
		echo "  â€¢ Airflow:  http://$${SERVER_IP:-localhost}:$${AIRFLOW_PORT:-8080} (admin/admin)"; \
		echo "  â€¢ Jupyter:  http://$${SERVER_IP:-localhost}:$${JUPYTER_PORT:-8888}"; \
		echo "  â€¢ MinIO:    http://$${SERVER_IP:-localhost}:$${MINIO_CONSOLE_PORT:-9001} (minioadmin/minioadmin123)"; \
		echo "  â€¢ Spark UI: http://$${SERVER_IP:-localhost}:4040 (via Jupyter)"; \
	else \
		echo "  â€¢ Airflow:  http://localhost:8080 (admin/admin)"; \
		echo "  â€¢ Jupyter:  http://localhost:8888"; \
		echo "  â€¢ MinIO:    http://localhost:9001 (minioadmin/minioadmin123)"; \
		echo "  â€¢ Spark UI: http://localhost:4040 (via Jupyter)"; \
	fi

stop-minimal: ## ğŸ›‘ Para ambiente mÃ­nimo
	@echo "$(YELLOW)ğŸ›‘ Parando ambiente mÃ­nimo...$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.minimal.yml down; \
	else \
		sudo docker-compose -f docker-compose.minimal.yml down; \
	fi

stop-all: ## ğŸ›‘ Para TODOS os containers (todos os ambientes)
	@echo "$(RED)ğŸ›‘ Parando TODOS os containers BigData...$(NC)"
	@echo "$(YELLOW)ğŸ“¦ Parando ambiente completo...$(NC)"
	@if groups | grep -q docker; then \
		docker-compose down 2>/dev/null || true; \
	else \
		sudo docker-compose down 2>/dev/null || true; \
	fi
	@echo "$(YELLOW)ğŸ§ª Parando ambiente lab...$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.lab.yml down 2>/dev/null || true; \
	else \
		sudo docker-compose -f docker-compose.lab.yml down 2>/dev/null || true; \
	fi
	@echo "$(YELLOW)ğŸ”¬ Parando ambiente minimal...$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.minimal.yml down 2>/dev/null || true; \
	else \
		sudo docker-compose -f docker-compose.minimal.yml down 2>/dev/null || true; \
	fi
	@echo "$(YELLOW)ğŸ§¹ Removendo containers Ã³rfÃ£os...$(NC)"
	@if groups | grep -q docker; then \
		docker container prune -f 2>/dev/null || true; \
	else \
		sudo docker container prune -f 2>/dev/null || true; \
	fi
	@echo "$(GREEN)âœ… Todos os containers BigData foram parados!$(NC)"

help: ## ğŸ“– Mostra esta ajuda
	@echo "$(BLUE)ğŸš€ Ambiente BigData - Comandos DisponÃ­veis$(NC)"
	@echo "================================================"
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## / {printf "$(GREEN)%-15s$(NC) %s\n", $$1, $$2}' $(MAKEFILE_LIST)
	@echo ""
	@echo "$(YELLOW)ğŸ’¡ Exemplos de uso:$(NC)"
	@echo "  make start     # Inicia todo o ambiente"
	@echo "  make status    # Verifica status dos serviÃ§os"
	@echo "  make logs      # Mostra logs de todos os serviÃ§os"
	@echo "  make stop      # Para o ambiente"

start: check-env ## ğŸš€ Inicia todo o ambiente BigData
	@echo "$(BLUE)ğŸš€ Iniciando ambiente BigData...$(NC)"
	@if groups | grep -q docker; then \
		./scripts/start.sh; \
	else \
		echo "$(YELLOW)âš ï¸  UsuÃ¡rio nÃ£o estÃ¡ no grupo docker. Usando sudo temporariamente...$(NC)"; \
		echo "$(YELLOW)ğŸ’¡ Para evitar usar sudo, faÃ§a logout/login apÃ³s a instalaÃ§Ã£o do Docker$(NC)"; \
		sudo ./scripts/start.sh; \
	fi

stop: ## ğŸ›‘ Para todos os serviÃ§os
	@echo "$(YELLOW)ğŸ›‘ Parando ambiente BigData...$(NC)"
	@./scripts/stop.sh

restart: ## ğŸ”„ Reinicia todo o ambiente
	@echo "$(YELLOW)ğŸ”„ Reiniciando ambiente BigData...$(NC)"
	@make stop
	@sleep 5
	@make start

status: ## ğŸ“Š Verifica status dos serviÃ§os
	@./scripts/status.sh

ps-all: ## ğŸ“‹ Lista containers de TODOS os ambientes
	@echo "$(BLUE)ğŸ“‹ Containers de todos os ambientes BigData:$(NC)"
	@echo "$(YELLOW)ğŸ­ Ambiente Completo:$(NC)"
	@if groups | grep -q docker; then \
		docker-compose ps 2>/dev/null || echo "  Nenhum container rodando"; \
	else \
		sudo docker-compose ps 2>/dev/null || echo "  Nenhum container rodando"; \
	fi
	@echo ""
	@echo "$(YELLOW)ğŸ§ª Ambiente Lab:$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.lab.yml ps 2>/dev/null || echo "  Nenhum container rodando"; \
	else \
		sudo docker-compose -f docker-compose.lab.yml ps 2>/dev/null || echo "  Nenhum container rodando"; \
	fi
	@echo ""
	@echo "$(YELLOW)ğŸ”¬ Ambiente Minimal:$(NC)"
	@if groups | grep -q docker; then \
		docker-compose -f docker-compose.minimal.yml ps 2>/dev/null || echo "  Nenhum container rodando"; \
	else \
		sudo docker-compose -f docker-compose.minimal.yml ps 2>/dev/null || echo "  Nenhum container rodando"; \
	fi

## ğŸ”§ Comandos de Desenvolvimento

build: ## ğŸ—ï¸ Build das imagens customizadas
	@echo "$(BLUE)ğŸ—ï¸ Building imagens customizadas...$(NC)"
	@docker-compose build --no-cache jenkins

pull: ## â¬‡ï¸ Atualiza todas as imagens
	@echo "$(BLUE)â¬‡ï¸ Atualizando imagens...$(NC)"
	@docker-compose pull

rebuild: ## ğŸ”¨ Rebuild completo (pull + build)
	@make pull
	@make build

## ğŸ“Š Monitoramento e Logs

logs: ## ğŸ“‹ Mostra logs de todos os serviÃ§os
	@if groups | grep -q docker; then \
		docker-compose logs -f; \
	else \
		sudo docker-compose logs -f; \
	fi

logs-airflow: ## ğŸ“‹ Logs especÃ­ficos do Airflow
	@if groups | grep -q docker; then \
		docker-compose logs -f airflow-webserver airflow-scheduler airflow-worker; \
	else \
		sudo docker-compose logs -f airflow-webserver airflow-scheduler airflow-worker; \
	fi

logs-spark: ## ğŸ“‹ Logs especÃ­ficos do Spark
	@if groups | grep -q docker; then \
		docker-compose logs -f spark-master spark-worker-1 spark-worker-2; \
	else \
		sudo docker-compose logs -f spark-master spark-worker-1 spark-worker-2; \
	fi

ps: ## ğŸ“‹ Lista containers em execuÃ§Ã£o
	@if groups | grep -q docker; then \
		docker-compose ps; \
	else \
		sudo docker-compose ps; \
	fi

top: ## ğŸ“Š Mostra uso de recursos
	@if groups | grep -q docker; then \
		docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"; \
	else \
		sudo docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"; \
	fi

## ğŸ” Comandos de DiagnÃ³stico

health: ## ğŸ¥ Verifica saÃºde dos serviÃ§os
	@echo "$(BLUE)ğŸ¥ Verificando saÃºde dos serviÃ§os...$(NC)"
	@for service in $(SERVICES); do \
		echo -n "$$service: "; \
		if groups | grep -q docker; then \
			if docker-compose ps $$service | grep -q "Up"; then \
				echo "$(GREEN)âœ… Running$(NC)"; \
			else \
				echo "$(RED)âŒ Down$(NC)"; \
			fi; \
		else \
			if sudo docker-compose ps $$service | grep -q "Up"; then \
				echo "$(GREEN)âœ… Running$(NC)"; \
			else \
				echo "$(RED)âŒ Down$(NC)"; \
			fi; \
		fi; \
	done

check: ## ğŸ” Verifica configuraÃ§Ã£o e dependÃªncias
	@echo "$(BLUE)ğŸ” Verificando dependÃªncias...$(NC)"
	@if command -v docker >/dev/null 2>&1; then \
		echo "$(GREEN)âœ… Docker encontrado: $$(docker --version)$(NC)"; \
	else \
		echo "$(YELLOW)âš ï¸  Docker nÃ£o encontrado. Instale com: curl -fsSL https://get.docker.com | sh$(NC)"; \
	fi
	@if command -v docker-compose >/dev/null 2>&1; then \
		echo "$(GREEN)âœ… Docker Compose encontrado: $$(docker-compose --version)$(NC)"; \
	else \
		echo "$(YELLOW)âš ï¸  Docker Compose nÃ£o encontrado. Instale seguindo: https://docs.docker.com/compose/install/$(NC)"; \
	fi
	@echo "$(BLUE)ğŸ” Verificando configuraÃ§Ã£o...$(NC)"
	@if command -v docker-compose >/dev/null 2>&1; then \
		docker-compose config >/dev/null 2>&1 && echo "$(GREEN)âœ… docker-compose.yml vÃ¡lido$(NC)" || echo "$(RED)âŒ docker-compose.yml invÃ¡lido$(NC)"; \
	else \
		echo "$(YELLOW)âš ï¸  NÃ£o Ã© possÃ­vel validar docker-compose.yml sem Docker Compose$(NC)"; \
	fi

## ğŸ§ª Comandos de Teste

test: ## ğŸ§ª Executa testes de integraÃ§Ã£o
	@echo "$(BLUE)ğŸ§ª Executando testes de integraÃ§Ã£o...$(NC)"
	@make test-minio
	@make test-spark
	@make test-airflow

test-minio: ## ğŸ§ª Testa conexÃ£o com MinIO
	@echo "$(YELLOW)Testando MinIO...$(NC)"
	@docker-compose exec -T minio mc ls myminio/ >/dev/null 2>&1 && \
		echo "$(GREEN)âœ… MinIO OK$(NC)" || \
		echo "$(RED)âŒ MinIO falha$(NC)"

test-spark: ## ğŸ§ª Testa cluster Spark
	@echo "$(YELLOW)Testando Spark...$(NC)"
	@docker-compose exec -T spark-master spark-submit --version >/dev/null 2>&1 && \
		echo "$(GREEN)âœ… Spark OK$(NC)" || \
		echo "$(RED)âŒ Spark falha$(NC)"

test-airflow: ## ğŸ§ª Testa Airflow
	@echo "$(YELLOW)Testando Airflow...$(NC)"
	@if [ -f .env ]; then \
		. ./.env; \
		curl -s "http://$${SERVER_IP:-localhost}:$${AIRFLOW_PORT:-8080}/health" >/dev/null 2>&1 && \
			echo "$(GREEN)âœ… Airflow OK$(NC)" || \
			echo "$(RED)âŒ Airflow falha$(NC)"; \
	else \
		curl -s "http://localhost:8080/health" >/dev/null 2>&1 && \
			echo "$(GREEN)âœ… Airflow OK$(NC)" || \
			echo "$(RED)âŒ Airflow falha$(NC)"; \
	fi

## ğŸ—‚ï¸ Comandos de Dados

backup: ## ğŸ’¾ Backup dos dados
	@echo "$(BLUE)ğŸ’¾ Criando backup...$(NC)"
	@mkdir -p backups/$(shell date +%Y%m%d_%H%M%S)
	@docker-compose exec -T postgres pg_dump -U airflow airflow > backups/$(shell date +%Y%m%d_%H%M%S)/airflow_db.sql
	@echo "$(GREEN)âœ… Backup criado em backups/$(shell date +%Y%m%d_%H%M%S)/$(NC)"

clean: ## ğŸ§¹ Remove containers e volumes (CUIDADO!)
	@echo "$(RED)âš ï¸  ATENÃ‡ÃƒO: Isso removerÃ¡ TODOS os dados!$(NC)"
	@read -p "Tem certeza? [y/N]: " -n 1 -r; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		echo "\n$(YELLOW)ğŸ§¹ Limpando ambiente...$(NC)"; \
		./scripts/stop.sh --clean; \
	else \
		echo "\n$(GREEN)âœ… OperaÃ§Ã£o cancelada$(NC)"; \
	fi

clean-images: ## ğŸ§¹ Remove imagens nÃ£o utilizadas
	@echo "$(YELLOW)ğŸ§¹ Removendo imagens nÃ£o utilizadas...$(NC)"
	@docker system prune -f
	@docker image prune -f

## ğŸ”§ Comandos EspecÃ­ficos de ServiÃ§os

airflow-shell: ## ğŸš Acessa shell do Airflow
	@docker-compose exec airflow-webserver bash

spark-shell: ## ğŸš Acessa Spark shell
	@docker-compose exec spark-master spark-shell --master spark://spark-master:7077

jupyter-shell: ## ğŸš Acessa shell do Jupyter
	@docker-compose exec jupyter bash

jenkins-shell: ## ğŸš Acessa shell do Jenkins
	@docker-compose exec jenkins bash

minio-shell: ## ğŸš Acessa shell do MinIO
	@docker-compose exec minio bash

## ğŸ“¦ Comandos de Deploy

install-docker: ## ğŸ³ Instala Docker e Docker Compose
	@echo "$(BLUE)ğŸ³ Instalando Docker...$(NC)"
	@if command -v docker >/dev/null 2>&1; then \
		echo "$(GREEN)âœ… Docker jÃ¡ estÃ¡ instalado$(NC)"; \
	else \
		echo "$(YELLOW)ğŸ“¦ Instalando Docker...$(NC)"; \
		curl -fsSL https://get.docker.com | sh; \
		sudo usermod -aG docker $$USER; \
		echo "$(GREEN)âœ… Docker instalado! FaÃ§a logout/login para usar sem sudo$(NC)"; \
	fi
	@if command -v docker-compose >/dev/null 2>&1; then \
		echo "$(GREEN)âœ… Docker Compose jÃ¡ estÃ¡ instalado$(NC)"; \
	else \
		echo "$(YELLOW)ğŸ“¦ Instalando Docker Compose...$(NC)"; \
		sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$$(uname -s)-$$(uname -m)" -o /usr/local/bin/docker-compose; \
		sudo chmod +x /usr/local/bin/docker-compose; \
		echo "$(GREEN)âœ… Docker Compose instalado!$(NC)"; \
	fi

submit-spark: ## âš¡ Submete job Spark de exemplo
	@echo "$(BLUE)âš¡ Submetendo job Spark...$(NC)"
	@docker-compose exec spark-master spark-submit \
		--master $${SPARK_MASTER_URL:-spark://spark-master:7077} \
		--executor-memory 1g \
		--executor-cores 1 \
		$${SPARK_APPS_PATH:-/opt/bitnami/spark/apps}/example_spark_minio.py

spark-shell: ## âš¡ Abre Spark shell interativo
	@echo "$(BLUE)âš¡ Abrindo Spark shell...$(NC)"
	@docker-compose exec spark-master spark-shell \
		--master $${SPARK_MASTER_URL:-spark://spark-master:7077}

install-deps: ## ğŸ“¦ Instala dependÃªncias adicionais
	@echo "$(BLUE)ğŸ“¦ Instalando dependÃªncias adicionais...$(NC)"
	@docker-compose exec airflow-webserver pip install -r /opt/airflow/requirements.txt

## ğŸŒ Comandos de Rede

ports: ## ğŸŒ Lista portas utilizadas
	@echo "$(BLUE)ğŸŒ Portas utilizadas pelo ambiente:$(NC)"
	@echo "  â€¢ Airflow:     http://$(SERVER_IP):$(AIRFLOW_PORT)"
	@echo "  â€¢ Spark UI:    http://$(SERVER_IP):$(SPARK_UI_PORT)" 
	@echo "  â€¢ MinIO:       http://$(SERVER_IP):$(MINIO_CONSOLE_PORT)"
	@echo "  â€¢ Jenkins:     http://$(SERVER_IP):$(JENKINS_PORT)"
	@echo "  â€¢ Jupyter:     http://$(SERVER_IP):$(JUPYTER_PORT)"
	@echo "  â€¢ Flower:      http://$(SERVER_IP):$(FLOWER_PORT)"

open: ## ğŸŒ Abre todas as interfaces web
	@echo "$(BLUE)ğŸŒ Abrindo interfaces web...$(NC)"
	@if [ -f .env ]; then \
		. ./.env; \
		command -v xdg-open >/dev/null 2>&1 && { \
			xdg-open "http://$${SERVER_IP:-localhost}:$${AIRFLOW_PORT:-8080}" & \
			xdg-open "http://$${SERVER_IP:-localhost}:$${SPARK_UI_PORT:-8081}" & \
			xdg-open "http://$${SERVER_IP:-localhost}:$${MINIO_CONSOLE_PORT:-9001}" & \
			xdg-open "http://$${SERVER_IP:-localhost}:$${JENKINS_PORT:-8082}" & \
			xdg-open "http://$${SERVER_IP:-localhost}:$${JUPYTER_PORT:-8888}" & \
			echo "$(GREEN)âœ… Interfaces abertas no navegador$(NC)"; \
		} || echo "$(YELLOW)âš ï¸  xdg-open nÃ£o disponÃ­vel. Abra manualmente as URLs listadas em 'make ports'$(NC)"; \
	else \
		command -v xdg-open >/dev/null 2>&1 && { \
			xdg-open "http://localhost:8080" & \
			xdg-open "http://localhost:8081" & \
			xdg-open "http://localhost:9001" & \
			xdg-open "http://localhost:8082" & \
			xdg-open "http://localhost:8888" & \
			echo "$(GREEN)âœ… Interfaces abertas no navegador$(NC)"; \
		} || echo "$(YELLOW)âš ï¸  xdg-open nÃ£o disponÃ­vel. Abra manualmente as URLs listadas em 'make ports'$(NC)"; \
	fi

##  Comandos de InformaÃ§Ã£o

info: ## â„¹ï¸ InformaÃ§Ãµes do ambiente
	@echo "$(BLUE)â„¹ï¸  InformaÃ§Ãµes do Ambiente BigData$(NC)"
	@echo "================================================"
	@echo "Projeto: $(PROJECT_NAME)"
	@echo "Compose File: $(COMPOSE_FILE)"
	@echo "Services: $(words $(SERVICES)) serviÃ§os"
	@echo ""
	@echo "$(YELLOW)ğŸ’¾ Uso de disco:$(NC)"
	@df -h . | tail -1
	@echo ""
	@echo "$(YELLOW)ğŸ³ Containers:$(NC)"
	@if groups | grep -q docker; then \
		docker-compose ps --format "table {{.Name}}\t{{.State}}\t{{.Ports}}" 2>/dev/null || echo "Nenhum container em execuÃ§Ã£o"; \
	else \
		sudo docker-compose ps --format "table {{.Name}}\t{{.State}}\t{{.Ports}}" 2>/dev/null || echo "Nenhum container em execuÃ§Ã£o"; \
	fi

version: ## ğŸ“‹ VersÃµes dos componentes
	@echo "$(BLUE)ğŸ“‹ VersÃµes dos Componentes$(NC)"
	@echo "================================================"
	@echo "Docker: $$(docker --version)"
	@echo "Docker Compose: $$(docker-compose --version)"
	@echo ""
	@echo "$(YELLOW)VersÃµes dos ServiÃ§os:$(NC)"
	@echo "Airflow: $$(docker-compose exec -T airflow-webserver airflow version 2>/dev/null || echo 'N/A')"
	@echo "Spark: $$(docker-compose exec -T spark-master spark-submit --version 2>&1 | head -1 || echo 'N/A')"
	@echo "PostgreSQL: $$(docker-compose exec -T postgres psql --version 2>/dev/null || echo 'N/A')"

## ğŸƒâ€â™‚ï¸ Comandos RÃ¡pidos

quick-start: check ## âš¡ Start rÃ¡pido (com verificaÃ§Ãµes)
	@make start

dev: ## ğŸ‘¨â€ğŸ’» Modo desenvolvedor (com logs)
	@make start
	@make logs

prod: ## ğŸ­ Modo produÃ§Ã£o (em background)
	@make start
	@echo "$(GREEN)âœ… Ambiente iniciado em modo produÃ§Ã£o$(NC)"
	@echo "$(BLUE)ğŸ’¡ Use 'make status' para verificar os serviÃ§os$(NC)"

requirements: ## ğŸ“‹ Mostra requisitos de sistema
	@echo "$(BLUE)ğŸ“‹ Requisitos de Sistema$(NC)"
	@echo "================================================"
	@echo "$(YELLOW)ğŸ­ Ambiente Completo (ProduÃ§Ã£o):$(NC)"
	@echo "  â€¢ RAM: 10-12GB"
	@echo "  â€¢ CPU: 6-8 cores"
	@echo "  â€¢ Disk: 20GB"
	@echo "  â€¢ ServiÃ§os: Todos (Airflow + Spark + MinIO + Jenkins + Jupyter)"
	@echo ""
	@echo "$(YELLOW)ğŸ”¬ Ambiente MÃ­nimo (4GB):$(NC)"
	@echo "  â€¢ RAM: 3-4GB"
	@echo "  â€¢ CPU: 2 cores"
	@echo "  â€¢ Disk: 5-8GB"
	@echo "  â€¢ ServiÃ§os: Airflow Standalone + Jupyter/Spark Local + MinIO"
	@echo ""
	@echo "$(YELLOW)ğŸ§ª Ambiente LaboratÃ³rio:$(NC)"
	@echo "  â€¢ RAM: 6-8GB"
	@echo "  â€¢ CPU: 4 cores"
	@echo "  â€¢ Disk: 10-15GB"
	@echo "  â€¢ ServiÃ§os: Airflow + Spark + MinIO + Jupyter (sem Jenkins)"
	@echo ""
	@echo "$(GREEN)ğŸ’¡ RecomendaÃ§Ã£o:$(NC)"
	@echo "  â€¢ Para mÃ¡quinas fracas: make minimal"
	@echo "  â€¢ Para aprendizado: make lab"
	@echo "  â€¢ Para desenvolvimento: make start"
	@echo "  â€¢ Para produÃ§Ã£o: make prod"

## ğŸ¯ Comandos EspecÃ­ficos por ServiÃ§o

# PostgreSQL
start-postgres: ## ğŸ˜ Inicia apenas PostgreSQL
	@echo "$(BLUE)ğŸ˜ Iniciando PostgreSQL...$(NC)"
	@docker-compose up -d postgres
	@sleep 3
	@make health-postgres

stop-postgres: ## ğŸ˜ Para PostgreSQL
	@echo "$(BLUE)ğŸ˜ Parando PostgreSQL...$(NC)"
	@docker-compose stop postgres

restart-postgres: ## ğŸ˜ Reinicia PostgreSQL
	@echo "$(BLUE)ğŸ˜ Reiniciando PostgreSQL...$(NC)"
	@make stop-postgres
	@sleep 2
	@make start-postgres

logs-postgres: ## ğŸ˜ Logs do PostgreSQL
	@echo "$(BLUE)ğŸ˜ Logs do PostgreSQL:$(NC)"
	@docker-compose logs -f postgres

shell-postgres: ## ğŸ˜ Shell no PostgreSQL
	@echo "$(BLUE)ğŸ˜ Conectando ao PostgreSQL...$(NC)"
	@docker-compose exec postgres psql -U airflow -d airflow

health-postgres: ## ğŸ˜ Verifica saÃºde do PostgreSQL
	@echo -n "$(BLUE)ğŸ˜ PostgreSQL: $(NC)"
	@if docker-compose ps postgres 2>/dev/null | grep -q "Up"; then \
		if docker-compose exec -T postgres pg_isready -U airflow >/dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

# Redis
start-redis: ## ğŸ“® Inicia apenas Redis
	@echo "$(BLUE)ğŸ“® Iniciando Redis...$(NC)"
	@docker-compose up -d redis
	@sleep 2
	@make health-redis

stop-redis: ## ğŸ“® Para Redis
	@echo "$(BLUE)ğŸ“® Parando Redis...$(NC)"
	@docker-compose stop redis

restart-redis: ## ğŸ“® Reinicia Redis
	@echo "$(BLUE)ğŸ“® Reiniciando Redis...$(NC)"
	@make stop-redis
	@sleep 2
	@make start-redis

logs-redis: ## ğŸ“® Logs do Redis
	@echo "$(BLUE)ğŸ“® Logs do Redis:$(NC)"
	@docker-compose logs -f redis

shell-redis: ## ğŸ“® Shell no Redis
	@echo "$(BLUE)ğŸ“® Conectando ao Redis...$(NC)"
	@docker-compose exec redis redis-cli

health-redis: ## ğŸ“® Verifica saÃºde do Redis
	@echo -n "$(BLUE)ğŸ“® Redis: $(NC)"
	@if docker-compose ps redis 2>/dev/null | grep -q "Up"; then \
		if docker-compose exec -T redis redis-cli ping >/dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

# MinIO
start-minio: ## ğŸ—‚ï¸ Inicia apenas MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Iniciando MinIO...$(NC)"
	@docker-compose up -d minio
	@sleep 3
	@make health-minio

stop-minio: ## ğŸ—‚ï¸ Para MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Parando MinIO...$(NC)"
	@docker-compose stop minio

restart-minio: ## ğŸ—‚ï¸ Reinicia MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Reiniciando MinIO...$(NC)"
	@make stop-minio
	@sleep 2
	@make start-minio

logs-minio: ## ğŸ—‚ï¸ Logs do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Logs do MinIO:$(NC)"
	@docker-compose logs -f minio

shell-minio: ## ğŸ—‚ï¸ Shell no MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Conectando ao MinIO...$(NC)"
	@docker-compose exec minio sh

health-minio: ## ğŸ—‚ï¸ Verifica saÃºde do MinIO
	@echo -n "$(BLUE)ğŸ—‚ï¸ MinIO: $(NC)"
	@if docker-compose ps minio 2>/dev/null | grep -q "Up"; then \
		if timeout 5 curl -s http://$(SERVER_IP):$(MINIO_CONSOLE_PORT)/minio/health/live > /dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

open-minio: ## ğŸ—‚ï¸ Abre interface do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Abrindo MinIO Console...$(NC)"
	@command -v xdg-open >/dev/null 2>&1 && xdg-open "http://$(SERVER_IP):$(MINIO_CONSOLE_PORT)" || echo "$(YELLOW)âš ï¸  Abra: http://$(SERVER_IP):$(MINIO_CONSOLE_PORT)$(NC)"

# Airflow
start-airflow: ## âœˆï¸ Inicia todos os serviÃ§os do Airflow
	@echo "$(BLUE)âœˆï¸ Iniciando Airflow (dependÃªncias incluÃ­das)...$(NC)"
	@make start-postgres
	@make start-redis
	@sleep 5
	@docker-compose up -d airflow-webserver airflow-scheduler airflow-worker
	@sleep 10
	@make health-airflow

stop-airflow: ## âœˆï¸ Para todos os serviÃ§os do Airflow
	@echo "$(BLUE)âœˆï¸ Parando Airflow...$(NC)"
	@docker-compose stop airflow-webserver airflow-scheduler airflow-worker

restart-airflow: ## âœˆï¸ Reinicia Airflow
	@echo "$(BLUE)âœˆï¸ Reiniciando Airflow...$(NC)"
	@make stop-airflow
	@sleep 3
	@make start-airflow

logs-airflow-webserver: ## âœˆï¸ Logs do Airflow Webserver
	@echo "$(BLUE)âœˆï¸ Logs do Airflow Webserver:$(NC)"
	@docker-compose logs -f airflow-webserver

logs-airflow-scheduler: ## âœˆï¸ Logs do Airflow Scheduler
	@echo "$(BLUE)âœˆï¸ Logs do Airflow Scheduler:$(NC)"
	@docker-compose logs -f airflow-scheduler

logs-airflow-worker: ## âœˆï¸ Logs do Airflow Worker
	@echo "$(BLUE)âœˆï¸ Logs do Airflow Worker:$(NC)"
	@docker-compose logs -f airflow-worker

shell-airflow: ## âœˆï¸ Shell no Airflow
	@echo "$(BLUE)âœˆï¸ Conectando ao Airflow...$(NC)"
	@docker-compose exec airflow-webserver bash

health-airflow: ## âœˆï¸ Verifica saÃºde do Airflow
	@echo "$(BLUE)âœˆï¸ Verificando Airflow:$(NC)"
	@echo -n "  â€¢ Webserver: "
	@if docker-compose ps airflow-webserver 2>/dev/null | grep -q "Up"; then \
		if timeout 10 curl -s http://$(SERVER_IP):$(AIRFLOW_PORT)/health > /dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi
	@echo -n "  â€¢ Scheduler: "
	@if docker-compose ps airflow-scheduler 2>/dev/null | grep -q "Up"; then \
		echo "$(GREEN)âœ… Running$(NC)"; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi
	@echo -n "  â€¢ Worker: "
	@if docker-compose ps airflow-worker 2>/dev/null | grep -q "Up"; then \
		echo "$(GREEN)âœ… Running$(NC)"; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

open-airflow: ## âœˆï¸ Abre interface do Airflow
	@echo "$(BLUE)âœˆï¸ Abrindo Airflow...$(NC)"
	@command -v xdg-open >/dev/null 2>&1 && xdg-open "http://$(SERVER_IP):$(AIRFLOW_PORT)" || echo "$(YELLOW)âš ï¸  Abra: http://$(SERVER_IP):$(AIRFLOW_PORT)$(NC)"

# Spark
start-spark: ## âš¡ Inicia cluster Spark
	@echo "$(BLUE)âš¡ Iniciando Spark cluster...$(NC)"
	@docker-compose up -d spark-master spark-worker-1 spark-worker-2
	@sleep 5
	@make health-spark

stop-spark: ## âš¡ Para cluster Spark
	@echo "$(BLUE)âš¡ Parando Spark cluster...$(NC)"
	@docker-compose stop spark-master spark-worker-1 spark-worker-2

restart-spark: ## âš¡ Reinicia cluster Spark
	@echo "$(BLUE)âš¡ Reiniciando Spark cluster...$(NC)"
	@make stop-spark
	@sleep 3
	@make start-spark

logs-spark-master: ## âš¡ Logs do Spark Master
	@echo "$(BLUE)âš¡ Logs do Spark Master:$(NC)"
	@docker-compose logs -f spark-master

logs-spark-worker: ## âš¡ Logs dos Spark Workers
	@echo "$(BLUE)âš¡ Logs dos Spark Workers:$(NC)"
	@docker-compose logs -f spark-worker-1 spark-worker-2

shell-spark: ## âš¡ Shell no Spark Master
	@echo "$(BLUE)âš¡ Conectando ao Spark Master...$(NC)"
	@docker-compose exec spark-master bash

health-spark: ## âš¡ Verifica saÃºde do Spark
	@echo "$(BLUE)âš¡ Verificando Spark:$(NC)"
	@echo -n "  â€¢ Master: "
	@if docker-compose ps spark-master 2>/dev/null | grep -q "Up"; then \
		if timeout 5 curl -s http://$(SERVER_IP):$(SPARK_UI_PORT) > /dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi
	@echo -n "  â€¢ Workers: "
	@if docker-compose ps spark-worker-1 spark-worker-2 | grep -q "Up.*Up"; then \
		echo "$(GREEN)âœ… Running$(NC)"; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

open-spark: ## âš¡ Abre interface do Spark
	@echo "$(BLUE)âš¡ Abrindo Spark UI...$(NC)"
	@command -v xdg-open >/dev/null 2>&1 && xdg-open "http://$(SERVER_IP):$(SPARK_UI_PORT)" || echo "$(YELLOW)âš ï¸  Abra: http://$(SERVER_IP):$(SPARK_UI_PORT)$(NC)"

# Jupyter
start-jupyter: ## ğŸ““ Inicia Jupyter
	@echo "$(BLUE)ğŸ““ Iniciando Jupyter...$(NC)"
	@docker-compose up -d jupyter
	@sleep 5
	@make health-jupyter

stop-jupyter: ## ğŸ““ Para Jupyter
	@echo "$(BLUE)ğŸ““ Parando Jupyter...$(NC)"
	@docker-compose stop jupyter

restart-jupyter: ## ğŸ““ Reinicia Jupyter
	@echo "$(BLUE)ğŸ““ Reiniciando Jupyter...$(NC)"
	@make stop-jupyter
	@sleep 2
	@make start-jupyter

logs-jupyter: ## ğŸ““ Logs do Jupyter
	@echo "$(BLUE)ğŸ““ Logs do Jupyter:$(NC)"
	@docker-compose logs -f jupyter

shell-jupyter: ## ğŸ““ Shell no Jupyter
	@echo "$(BLUE)ğŸ““ Conectando ao Jupyter...$(NC)"
	@docker-compose exec jupyter bash

health-jupyter: ## ğŸ““ Verifica saÃºde do Jupyter
	@echo -n "$(BLUE)ğŸ““ Jupyter: $(NC)"
	@if docker-compose ps jupyter 2>/dev/null | grep -q "Up"; then \
		if timeout 5 curl -s http://$(SERVER_IP):$(JUPYTER_PORT) > /dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

open-jupyter: ## ğŸ““ Abre interface do Jupyter
	@echo "$(BLUE)ğŸ““ Abrindo Jupyter...$(NC)"
	@echo "$(YELLOW)ğŸ’¡ Use a senha: jupyter$(NC)"
	@command -v xdg-open >/dev/null 2>&1 && xdg-open "http://$(SERVER_IP):$(JUPYTER_PORT)" || echo "$(YELLOW)âš ï¸  Abra: http://$(SERVER_IP):$(JUPYTER_PORT)$(NC)"

# Jenkins  
start-jenkins: ## ğŸ—ï¸ Inicia Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Iniciando Jenkins...$(NC)"
	@docker-compose up -d jenkins
	@sleep 10
	@make health-jenkins

stop-jenkins: ## ğŸ—ï¸ Para Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Parando Jenkins...$(NC)"
	@docker-compose stop jenkins

restart-jenkins: ## ğŸ—ï¸ Reinicia Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Reiniciando Jenkins...$(NC)"
	@make stop-jenkins
	@sleep 3
	@make start-jenkins

logs-jenkins: ## ğŸ—ï¸ Logs do Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Logs do Jenkins:$(NC)"
	@docker-compose logs -f jenkins

shell-jenkins: ## ğŸ—ï¸ Shell no Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Conectando ao Jenkins...$(NC)"
	@docker-compose exec jenkins bash

health-jenkins: ## ğŸ—ï¸ Verifica saÃºde do Jenkins
	@echo -n "$(BLUE)ğŸ—ï¸ Jenkins: $(NC)"
	@if docker-compose ps jenkins 2>/dev/null | grep -q "Up"; then \
		if timeout 10 curl -s http://$(SERVER_IP):$(JENKINS_PORT) > /dev/null 2>&1; then \
			echo "$(GREEN)âœ… Healthy$(NC)"; \
		else \
			echo "$(YELLOW)âš ï¸  Starting$(NC)"; \
		fi; \
	else \
		echo "$(RED)âŒ Down$(NC)"; \
	fi

open-jenkins: ## ğŸ—ï¸ Abre interface do Jenkins
	@echo "$(BLUE)ğŸ—ï¸ Abrindo Jenkins...$(NC)"
	@command -v xdg-open >/dev/null 2>&1 && xdg-open "http://$(SERVER_IP):$(JENKINS_PORT)" || echo "$(YELLOW)âš ï¸  Abra: http://$(SERVER_IP):$(JENKINS_PORT)$(NC)"

## ğŸ”§ Comandos de Troubleshooting por ServiÃ§o

# Reset especÃ­fico por serviÃ§o (remove dados/configuraÃ§Ãµes)
reset-postgres: ## ğŸ˜ Reset completo do PostgreSQL (REMOVE DADOS!)
	@echo "$(RED)âš ï¸  ATENÃ‡ÃƒO: Isso irÃ¡ REMOVER TODOS OS DADOS do PostgreSQL!$(NC)"
	@read -p "Tem certeza? Digite 'yes' para confirmar: " confirm && [ "$$confirm" = "yes" ] || exit 1
	@echo "$(BLUE)ğŸ˜ Resetando PostgreSQL...$(NC)"
	@make stop-postgres
	@docker-compose rm -f postgres
	@docker volume rm bigdata_postgres_data 2>/dev/null || true
	@echo "$(GREEN)âœ… PostgreSQL resetado$(NC)"

reset-minio: ## ğŸ—‚ï¸ Reset completo do MinIO (REMOVE DADOS!)
	@echo "$(RED)âš ï¸  ATENÃ‡ÃƒO: Isso irÃ¡ REMOVER TODOS OS DADOS do MinIO!$(NC)"
	@read -p "Tem certeza? Digite 'yes' para confirmar: " confirm && [ "$$confirm" = "yes" ] || exit 1
	@echo "$(BLUE)ğŸ—‚ï¸ Resetando MinIO...$(NC)"
	@make stop-minio
	@docker-compose rm -f minio
	@docker volume rm bigdata_minio_data 2>/dev/null || true
	@echo "$(GREEN)âœ… MinIO resetado$(NC)"

reset-airflow: ## âœˆï¸ Reset completo do Airflow (REMOVE LOGS/CONFIGS!)
	@echo "$(RED)âš ï¸  ATENÃ‡ÃƒO: Isso irÃ¡ REMOVER logs e configuraÃ§Ãµes do Airflow!$(NC)"
	@read -p "Tem certeza? Digite 'yes' para confirmar: " confirm && [ "$$confirm" = "yes" ] || exit 1
	@echo "$(BLUE)âœˆï¸ Resetando Airflow...$(NC)"
	@make stop-airflow
	@docker-compose rm -f airflow-webserver airflow-scheduler airflow-worker
	@docker volume rm bigdata_airflow_logs 2>/dev/null || true
	@echo "$(GREEN)âœ… Airflow resetado$(NC)"

# Rebuild especÃ­fico por serviÃ§o
rebuild-postgres: ## ğŸ˜ Rebuild do PostgreSQL
	@echo "$(BLUE)ğŸ˜ Rebuild do PostgreSQL...$(NC)"
	@make stop-postgres
	@docker-compose rm -f postgres
	@docker-compose pull postgres
	@make start-postgres

rebuild-minio: ## ğŸ—‚ï¸ Rebuild do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Rebuild do MinIO...$(NC)"
	@make stop-minio
	@docker-compose rm -f minio
	@docker-compose pull minio
	@make start-minio

rebuild-airflow: ## âœˆï¸ Rebuild do Airflow
	@echo "$(BLUE)âœˆï¸ Rebuild do Airflow...$(NC)"
	@make stop-airflow
	@docker-compose rm -f airflow-webserver airflow-scheduler airflow-worker
	@docker-compose pull apache/airflow
	@make start-airflow

rebuild-spark: ## âš¡ Rebuild do Spark
	@echo "$(BLUE)âš¡ Rebuild do Spark...$(NC)"
	@make stop-spark
	@docker-compose rm -f spark-master spark-worker-1 spark-worker-2
	@docker-compose pull bitnami/spark
	@make start-spark

rebuild-jupyter: ## ğŸ““ Rebuild do Jupyter
	@echo "$(BLUE)ğŸ““ Rebuild do Jupyter...$(NC)"
	@make stop-jupyter
	@docker-compose rm -f jupyter
	@docker-compose pull jupyter/all-spark-notebook
	@make start-jupyter

# Debug especÃ­fico por serviÃ§o
debug-postgres: ## ğŸ˜ Debug do PostgreSQL
	@echo "$(BLUE)ğŸ˜ Debug do PostgreSQL:$(NC)"
	@echo "$(YELLOW)ğŸ“Š Status do container:$(NC)"
	@docker-compose ps postgres
	@echo "$(YELLOW)ğŸ” Ãšltimos logs:$(NC)"
	@docker-compose logs --tail=20 postgres
	@echo "$(YELLOW)ğŸ©º Teste de conexÃ£o:$(NC)"
	@docker-compose exec postgres pg_isready -U airflow || echo "$(RED)âŒ PostgreSQL nÃ£o estÃ¡ respondendo$(NC)"

debug-minio: ## ğŸ—‚ï¸ Debug do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Debug do MinIO:$(NC)"
	@echo "$(YELLOW)ğŸ“Š Status do container:$(NC)"
	@docker-compose ps minio
	@echo "$(YELLOW)ğŸ” Ãšltimos logs:$(NC)"
	@docker-compose logs --tail=20 minio
	@echo "$(YELLOW)ğŸ©º Teste de conectividade:$(NC)"
	@curl -I http://$(SERVER_IP):$(MINIO_CONSOLE_PORT)/minio/health/live 2>/dev/null || echo "$(RED)âŒ MinIO nÃ£o estÃ¡ respondendo$(NC)"

debug-airflow: ## âœˆï¸ Debug completo do Airflow
	@echo "$(BLUE)âœˆï¸ Debug do Airflow:$(NC)"
	@echo "$(YELLOW)ğŸ“Š Status dos containers:$(NC)"
	@docker-compose ps airflow-webserver airflow-scheduler airflow-worker
	@echo "$(YELLOW)ğŸ” Logs do Webserver:$(NC)"
	@docker-compose logs --tail=10 airflow-webserver
	@echo "$(YELLOW)ğŸ” Logs do Scheduler:$(NC)"
	@docker-compose logs --tail=10 airflow-scheduler
	@echo "$(YELLOW)ğŸ©º Teste de conectividade:$(NC)"
	@curl -I http://$(SERVER_IP):$(AIRFLOW_PORT)/health 2>/dev/null || echo "$(RED)âŒ Airflow webserver nÃ£o estÃ¡ respondendo$(NC)"

debug-spark: ## âš¡ Debug do Spark
	@echo "$(BLUE)âš¡ Debug do Spark:$(NC)"
	@echo "$(YELLOW)ğŸ“Š Status dos containers:$(NC)"
	@docker-compose ps spark-master spark-worker-1 spark-worker-2
	@echo "$(YELLOW)ğŸ” Logs do Master:$(NC)"
	@docker-compose logs --tail=10 spark-master
	@echo "$(YELLOW)ğŸ©º Teste de conectividade:$(NC)"
	@curl -I http://$(SERVER_IP):$(SPARK_UI_PORT) 2>/dev/null || echo "$(RED)âŒ Spark UI nÃ£o estÃ¡ respondendo$(NC)"

# VerificaÃ§Ã£o de dependÃªncias
check-deps-airflow: ## âœˆï¸ Verifica dependÃªncias do Airflow
	@echo "$(BLUE)âœˆï¸ Verificando dependÃªncias do Airflow:$(NC)"
	@echo -n "$(YELLOW)PostgreSQL: $(NC)"
	@make health-postgres
	@echo -n "$(YELLOW)Redis: $(NC)"
	@make health-redis
	@echo "$(YELLOW)RecomendaÃ§Ã£o: Inicie dependÃªncias com 'make start-postgres start-redis'$(NC)"

check-deps-spark: ## âš¡ Verifica dependÃªncias do Spark
	@echo "$(BLUE)âš¡ Verificando dependÃªncias do Spark:$(NC)"
	@echo "$(YELLOW)â„¹ï¸  Spark nÃ£o tem dependÃªncias obrigatÃ³rias, mas funciona melhor com MinIO$(NC)"
	@echo -n "$(YELLOW)MinIO (opcional): $(NC)"
	@make health-minio

# Status consolidado por serviÃ§o
status-database: ## ğŸ—„ï¸ Status de todos os bancos de dados
	@echo "$(BLUE)ğŸ—„ï¸ Status dos bancos de dados:$(NC)"
	@make health-postgres
	@make health-redis

status-storage: ## ğŸ—‚ï¸ Status dos sistemas de armazenamento
	@echo "$(BLUE)ğŸ—‚ï¸ Status do armazenamento:$(NC)"
	@make health-minio

status-compute: ## âš¡ Status dos sistemas de computaÃ§Ã£o
	@echo "$(BLUE)âš¡ Status da computaÃ§Ã£o:$(NC)"
	@make health-spark
	@make health-jupyter

status-orchestration: ## âœˆï¸ Status da orquestraÃ§Ã£o
	@echo "$(BLUE)âœˆï¸ Status da orquestraÃ§Ã£o:$(NC)"
	@make health-airflow
	@make health-jenkins

## ğŸ’¾ Comandos de Backup/Restore por ServiÃ§o

# Backup PostgreSQL
backup-postgres: ## ğŸ˜ Backup do PostgreSQL
	@echo "$(BLUE)ğŸ˜ Fazendo backup do PostgreSQL...$(NC)"
	@mkdir -p ./backups/postgres
	@docker-compose exec postgres pg_dump -U airflow airflow > ./backups/postgres/airflow_$(shell date +%Y%m%d_%H%M%S).sql
	@echo "$(GREEN)âœ… Backup salvo em ./backups/postgres/$(NC)"

restore-postgres: ## ğŸ˜ Restore do PostgreSQL
	@echo "$(BLUE)ğŸ˜ Listando backups disponÃ­veis:$(NC)"
	@ls -la ./backups/postgres/ 2>/dev/null || echo "$(YELLOW)âš ï¸  Nenhum backup encontrado$(NC)"
	@echo "$(YELLOW)ğŸ’¡ Para restaurar: docker-compose exec postgres psql -U airflow -d airflow < ./backups/postgres/ARQUIVO.sql$(NC)"

# Backup MinIO
backup-minio: ## ğŸ—‚ï¸ Backup dos dados do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Fazendo backup do MinIO...$(NC)"
	@mkdir -p ./backups/minio
	@docker run --rm -v bigdata_minio_data:/data -v $(PWD)/backups/minio:/backup alpine tar czf /backup/minio_data_$(shell date +%Y%m%d_%H%M%S).tar.gz -C /data .
	@echo "$(GREEN)âœ… Backup salvo em ./backups/minio/$(NC)"

restore-minio: ## ğŸ—‚ï¸ Restore dos dados do MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Listando backups disponÃ­veis:$(NC)"
	@ls -la ./backups/minio/ 2>/dev/null || echo "$(YELLOW)âš ï¸  Nenhum backup encontrado$(NC)"
	@echo "$(RED)âš ï¸  Para restaurar um backup especÃ­fico:$(NC)"
	@echo "$(YELLOW)1. Pare o MinIO: make stop-minio$(NC)"
	@echo "$(YELLOW)2. Execute: docker run --rm -v bigdata_minio_data:/data -v $(PWD)/backups/minio:/backup alpine tar xzf /backup/ARQUIVO.tar.gz -C /data$(NC)"
	@echo "$(YELLOW)3. Inicie o MinIO: make start-minio$(NC)"

# Backup Airflow
backup-airflow: ## âœˆï¸ Backup das configuraÃ§Ãµes do Airflow
	@echo "$(BLUE)âœˆï¸ Fazendo backup do Airflow...$(NC)"
	@mkdir -p ./backups/airflow
	@tar czf ./backups/airflow/airflow_configs_$(shell date +%Y%m%d_%H%M%S).tar.gz ./airflow/dags ./airflow/plugins ./airflow/config 2>/dev/null || true
	@docker run --rm -v bigdata_airflow_logs:/logs -v $(PWD)/backups/airflow:/backup alpine tar czf /backup/airflow_logs_$(shell date +%Y%m%d_%H%M%S).tar.gz -C /logs . 2>/dev/null || true
	@echo "$(GREEN)âœ… Backup salvo em ./backups/airflow/$(NC)"

restore-airflow: ## âœˆï¸ Restore das configuraÃ§Ãµes do Airflow
	@echo "$(BLUE)âœˆï¸ Listando backups disponÃ­veis:$(NC)"
	@ls -la ./backups/airflow/ 2>/dev/null || echo "$(YELLOW)âš ï¸  Nenhum backup encontrado$(NC)"
	@echo "$(RED)âš ï¸  Para restaurar configuraÃ§Ãµes:$(NC)"
	@echo "$(YELLOW)tar xzf ./backups/airflow/airflow_configs_TIMESTAMP.tar.gz$(NC)"
	@echo "$(RED)âš ï¸  Para restaurar logs:$(NC)"
	@echo "$(YELLOW)docker run --rm -v bigdata_airflow_logs:/logs -v $(PWD)/backups/airflow:/backup alpine tar xzf /backup/airflow_logs_TIMESTAMP.tar.gz -C /logs$(NC)"

# Backup completo de um serviÃ§o
full-backup-postgres: ## ğŸ˜ Backup completo PostgreSQL (dados + volume)
	@echo "$(BLUE)ğŸ˜ Backup completo do PostgreSQL...$(NC)"
	@mkdir -p ./backups/postgres
	@make backup-postgres
	@docker run --rm -v bigdata_postgres_data:/data -v $(PWD)/backups/postgres:/backup alpine tar czf /backup/postgres_volume_$(shell date +%Y%m%d_%H%M%S).tar.gz -C /data .
	@echo "$(GREEN)âœ… Backup completo salvo em ./backups/postgres/$(NC)"

full-backup-minio: ## ğŸ—‚ï¸ Backup completo MinIO
	@echo "$(BLUE)ğŸ—‚ï¸ Backup completo do MinIO...$(NC)"
	@make backup-minio

full-backup-airflow: ## âœˆï¸ Backup completo Airflow
	@echo "$(BLUE)âœˆï¸ Backup completo do Airflow...$(NC)"
	@make backup-airflow
	@make backup-postgres  # Airflow usa PostgreSQL

# Backup de todo o ambiente
backup-all: ## ğŸ’¾ Backup completo de todo o ambiente
	@echo "$(BLUE)ğŸ’¾ Fazendo backup completo do ambiente...$(NC)"
	@make full-backup-postgres
	@make full-backup-minio  
	@make full-backup-airflow
	@echo "$(YELLOW)ğŸ“‹ Salvando configuraÃ§Ãµes do ambiente...$(NC)"
	@mkdir -p ./backups/environment
	@cp .env ./backups/environment/env_$(shell date +%Y%m%d_%H%M%S).backup 2>/dev/null || true
	@cp docker-compose*.yml ./backups/environment/ 2>/dev/null || true
	@echo "$(GREEN)âœ… Backup completo finalizado em ./backups/$(NC)"

# Comandos de informaÃ§Ã£o sobre backups
list-backups: ## ğŸ’¾ Lista todos os backups disponÃ­veis
	@echo "$(BLUE)ğŸ’¾ Backups disponÃ­veis:$(NC)"
	@echo "$(YELLOW)ğŸ“‚ PostgreSQL:$(NC)"
	@ls -la ./backups/postgres/ 2>/dev/null || echo "  Nenhum backup"
	@echo "$(YELLOW)ğŸ“‚ MinIO:$(NC)"  
	@ls -la ./backups/minio/ 2>/dev/null || echo "  Nenhum backup"
	@echo "$(YELLOW)ğŸ“‚ Airflow:$(NC)"
	@ls -la ./backups/airflow/ 2>/dev/null || echo "  Nenhum backup"
	@echo "$(YELLOW)ğŸ“‚ Environment:$(NC)"
	@ls -la ./backups/environment/ 2>/dev/null || echo "  Nenhum backup"

clean-old-backups: ## ğŸ’¾ Remove backups antigos (>7 dias)
	@echo "$(BLUE)ğŸ’¾ Removendo backups antigos...$(NC)"
	@find ./backups -name "*.sql" -mtime +7 -delete 2>/dev/null || true
	@find ./backups -name "*.tar.gz" -mtime +7 -delete 2>/dev/null || true
	@find ./backups -name "*.backup" -mtime +7 -delete 2>/dev/null || true
	@echo "$(GREEN)âœ… Backups antigos removidos$(NC)"